{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "69c11acc",
      "metadata": {
        "id": "69c11acc"
      },
      "source": [
        "\n",
        "<style>\n",
        "/* Increase size for section headers */\n",
        "h2 { font-size: 2.5em !important; }\n",
        "h3 { font-size: 2.25em !important; }\n",
        "h4 { font-size: 1.75em !important; }\n",
        "</style>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c648f453",
      "metadata": {
        "id": "c648f453"
      },
      "source": [
        "# **Day 3: Introduction to Data Analysis with Pandas üêº**\n",
        "\n",
        "Welcome to Day 3! Today, we'll dive into **Pandas**, a powerful Python library essential for data analysis. By the end of this session, you'll be comfortable with the basics of manipulating and analyzing data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9564d3a6",
      "metadata": {
        "id": "9564d3a6"
      },
      "source": [
        "# **üéØ Goals for Today:**\n",
        "\n",
        "1.  Understand what Python **libraries** are and why they are useful.\n",
        "2.  Learn about **Pandas** and its primary data structures: **Series** and **DataFrame**.\n",
        "3.  Load data from a CSV file into a DataFrame.\n",
        "4.  Inspect and explore data to understand its structure and contents.\n",
        "5.  Perform data cleaning tasks like handling missing values and duplicates.\n",
        "6.  Transform data by creating new columns and changing data types.\n",
        "7.  Calculate basic statistics and perform simple aggregations.\n",
        "8.  Create basic visualizations (histograms, bar plots, scatter plots) to understand data patterns.\n",
        "9.  Practice with hands-on exercises and group activities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5358cfd8",
      "metadata": {
        "id": "5358cfd8"
      },
      "source": [
        "---\n",
        "# **1. What are Python Libraries? ü§î**\n",
        "\n",
        "Python libraries are collections of pre-written code (modules, functions, classes) that provide functionalities to perform specific tasks without you having to write the code from scratch. They extend Python's capabilities.\n",
        "\n",
        "**Common Libraries in Data Analysis:**\n",
        "* **Pandas:** For data manipulation and analysis (what we're learning today!).\n",
        "* **NumPy:** For numerical operations, especially with arrays.\n",
        "* **Matplotlib:** For creating static, animated, and interactive visualizations.\n",
        "* **Seaborn:** Built on Matplotlib, provides a high-level interface for drawing attractive statistical graphics.\n",
        "* **SciPy:** For scientific and technical computing.\n",
        "* **Scikit-learn:** For machine learning tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01949d33",
      "metadata": {
        "id": "01949d33"
      },
      "source": [
        "---\n",
        "# **2. Introduction to Pandas üêº**\n",
        "\n",
        "**Pandas** is a fast, powerful, flexible, and easy-to-use open-source data analysis and manipulation tool, built on top of the Python programming language. It's the go-to library for handling structured data.\n",
        "\n",
        "**Why use Pandas?**\n",
        "* Easily loads data from various sources (CSV, Excel, databases, etc.).\n",
        "* Provides rich data structures for holding and manipulating data.\n",
        "* Offers a wide range of functions for cleaning, transforming, merging, and reshaping data.\n",
        "* Integrates well with other data science libraries like NumPy and Matplotlib.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c12b37d8",
      "metadata": {
        "id": "c12b37d8"
      },
      "source": [
        "# **üõ†Ô∏è Setup: Import Libraries**\n",
        "\n",
        "First, we need to import the libraries we'll be using. **Pandas** is for data manipulation, and **Matplotlib** is for plotting. We use aliases (`pd`, `plt`) by convention to make them easier to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "744d2605",
      "metadata": {
        "id": "744d2605"
      },
      "outputs": [],
      "source": [
        "# Import pandas and matplotlib\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Core Pandas Data Structures:**\n",
        "\n",
        "# **2.1. Pandas Series**\n",
        "A **Series** is a one-dimensional labeled array capable of holding data of any type (integers, strings, floating-point numbers, Python objects, etc.). It's like a single column in a spreadsheet or a SQL table. Each element in a Series has an associated label, called an **index**."
      ],
      "metadata": {
        "id": "9psXZ0uplm1Q"
      },
      "id": "9psXZ0uplm1Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f7f2f6",
      "metadata": {
        "id": "99f7f2f6"
      },
      "outputs": [],
      "source": [
        "# Example 2.1.1: Create a Series from a list\n",
        "student_scores = pd.Series([90, 85, 77, 92, 88])\n",
        "print(\"Student Scores Series:\")\n",
        "print(student_scores)\n",
        "\n",
        "# Example 2.1.2: Create a Series with a custom index\n",
        "fruit_quantities = pd.Series([10, 15, 8, 12], index=['apples', 'bananas', 'cherries', 'dates'])\n",
        "print(\"\\nFruit Quantities Series:\")\n",
        "print(fruit_quantities)\n",
        "\n",
        "# Accessing an element using index\n",
        "print(\"\\nQuantity of bananas:\", fruit_quantities['bananas'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40269ca8",
      "metadata": {
        "id": "40269ca8"
      },
      "source": [
        "**Exercise 2.1.1:** Create a Pandas Series named `book_prices` with the following prices: `[15.99, 22.50, 12.75, 9.99]`. Print the Series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da918890",
      "metadata": {
        "id": "da918890"
      },
      "outputs": [],
      "source": [
        "# Exercise 2.1.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f0837f6",
      "metadata": {
        "id": "9f0837f6"
      },
      "source": [
        "**Exercise 2.1.2:** Create a Pandas Series named `subject_teachers` with subjects as indices `['Math', 'Science', 'History', 'English']` and teacher names as values `['Mr. Smith', 'Ms. Jones', 'Dr. Brown', 'Ms. Davis']`. Print the Series and then print the teacher for 'History'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc498a72",
      "metadata": {
        "id": "dc498a72"
      },
      "outputs": [],
      "source": [
        "# Exercise 2.1.2 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b303705",
      "metadata": {
        "id": "5b303705"
      },
      "source": [
        "# **‚ú® Group Activity 1: Series Operations ‚ú®**\n",
        "\n",
        "**Scenario:** You have a Series of product prices and want to apply a 10% discount.\n",
        "1. Create a Pandas Series named `original_prices` with values `[20, 50, 30, 75, 90]`.\n",
        "2. Try to calculate the discounted prices (original price - 10% of original price).\n",
        "3. **Buggy Code attempt:** `discounted_prices = original_prices - \"10%\"`\n",
        "4. Discuss: Why does this fail? How can you correctly calculate the discount (e.g., `original_prices * 0.90`)?\n",
        "5. Write the corrected code to calculate and print the `discounted_prices`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8942d89",
      "metadata": {
        "id": "a8942d89"
      },
      "outputs": [],
      "source": [
        "# Group Activity 1 Code Cell\n",
        "original_prices = pd.Series([20, 50, 30, 75, 90])\n",
        "# discounted_prices = original_prices - \"10%\" # This is buggy!\n",
        "# print(discounted_prices)\n",
        "\n",
        "# Write your corrected code here:\n",
        "discount_percentage = 0.10\n",
        "discounted_prices = original_prices * (1 - discount_percentage)\n",
        "print(\"Original Prices:\")\n",
        "print(original_prices)\n",
        "print(\"\\nDiscounted Prices (10% off):\")\n",
        "print(discounted_prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c52a88c",
      "metadata": {
        "id": "5c52a88c"
      },
      "source": [
        "# **2.2. Pandas DataFrame**\n",
        "A **DataFrame** is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). You can think of it as a spreadsheet, a SQL table, or a dictionary of Series objects. It's the most commonly used Pandas object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ea6909",
      "metadata": {
        "id": "e8ea6909"
      },
      "outputs": [],
      "source": [
        "# Example 2.2.1: Create a DataFrame from a dictionary of lists\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, 30, 22, 28],\n",
        "    'City': ['New York', 'Paris', 'London', 'Berlin']\n",
        "}\n",
        "df_people = pd.DataFrame(data)\n",
        "print(\"People DataFrame:\")\n",
        "print(df_people)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2.2.1: Create a DataFrame from a dictionary of lists with a custom index\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, 30, 22, 28],\n",
        "    'City': ['New York', 'Paris', 'London', 'Berlin']\n",
        "}\n",
        "\n",
        "# Define a custom index\n",
        "custom_index = ['ID101', 'ID102', 'ID103', 'ID104']\n",
        "\n",
        "# Create the DataFrame with the custom index\n",
        "df_people = pd.DataFrame(data, index=custom_index)\n",
        "\n",
        "print(\"People DataFrame with Custom Index:\")\n",
        "print(df_people)\n"
      ],
      "metadata": {
        "id": "E9JJ1C-lg9HV"
      },
      "id": "E9JJ1C-lg9HV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5ccd3c29",
      "metadata": {
        "id": "5ccd3c29"
      },
      "source": [
        "**Exercise 2.2.1:** Create a DataFrame named `df_products` with three columns: `Product_Name` (strings), `Price` (floats), and `In_Stock` (booleans). Include at least 3 rows of data. Print the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60d5531",
      "metadata": {
        "id": "c60d5531"
      },
      "outputs": [],
      "source": [
        "# Exercise 2.2.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0511d88",
      "metadata": {
        "id": "d0511d88"
      },
      "source": [
        "**Exercise 2.2.2:** Create a DataFrame named `df_temps` with rows indexed by `['Mon', 'Tue', 'Wed']` and columns for `['Morning_Temp', 'Evening_Temp']`. Populate it with some temperature data. Print the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "682f0aaf",
      "metadata": {
        "id": "682f0aaf"
      },
      "outputs": [],
      "source": [
        "# Exercise 2.2.2 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58184fb0",
      "metadata": {
        "id": "58184fb0"
      },
      "source": [
        "---\n",
        "# **3. Loading Data from CSV Files üìÑ**\n",
        "\n",
        "CSV (Comma Separated Values) files are a common way to store tabular data. Pandas makes it very easy to read data from CSV files into a DataFrame.\n",
        "\n",
        "**Key function:** `pd.read_csv('your_file_name.csv')`\n",
        "\n",
        "**For this notebook, we will assume you have a `student.csv` file in the same directory as this notebook with the following approximate structure:**\n",
        "```csv\n",
        "id,name,class,mark,gender\n",
        "1,John Deo,Four,75,female\n",
        "2,Max Ruin,Three,85,male\n",
        "3,Arnold,Three,55,male\n",
        "4,Krish Star,Four,60,female\n",
        "5,John Mike,Four,60,female\n",
        "6,Alex John,Four,55,male\n",
        "7,My John Rob,Fifth,78,male\n",
        "8,Asruid,Five,85,male\n",
        "9,Tes Qry,Six,78,\n",
        "10,Big John,Four,55,female\n",
        "11,Ronald,Six,89,female\n",
        "12,Recky,Six,94,female\n",
        "13,Kty,Seven,88,female\n",
        "14,Bigy,Seven,88,female\n",
        "15,Tade Row,Eight,88,male\n",
        "16,Gimmy,Four,88,male\n",
        "17, HONNY,Five,75,male\n",
        "18,KINN ENG,Six,98,female\n",
        "19,Linnea,Seven,69,female\n",
        "20,Jackly,Nine,65,female\n",
        "21,Babby John,Four,69,female\n",
        "22,Reggid,Seven,72,male\n",
        "23,Herod,Eight,79,male\n",
        "24,Tiddy Now,Seven,78,male\n",
        "25,Mikky,Seven,72,male\n",
        "26,Crelea,Seven,79,male\n",
        "27,Big Nose,Three,82,female\n",
        "28, Anto,Six,67,male\n",
        "29,Tes Qry,Six,78,\n",
        "30,Reppy Red,Six,79,female\n",
        "31,Malik,Five,82,male\n",
        "32,„Ç§„Éâ„É™,Four,75,male\n",
        "33,Monika,Nine,58,female\n",
        "34,Gain Toe,Seven,69,male\n",
        "35,BSR,Eight,92,male\n",
        "```\n",
        "*(You can create this file yourself, or I will provide code to create a sample DataFrame if the file is not found.)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a835a6",
      "metadata": {
        "id": "b6a835a6"
      },
      "outputs": [],
      "source": [
        "# 1. Read the file into a table called df\n",
        "df = pd.read_csv('student.csv')\n",
        "\n",
        "# 3. Peek at the first 5 rows to check your data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41dbeb84",
      "metadata": {
        "id": "41dbeb84"
      },
      "source": [
        "**Exercise 3.1:** Imagine you have another CSV file named `courses.csv` with columns `Course_ID`, `Course_Name`, `Credits`. Write the Python code to load this hypothetical file into a DataFrame called `df_courses`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddaa4d20",
      "metadata": {
        "id": "ddaa4d20"
      },
      "outputs": [],
      "source": [
        "# Exercise 3.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "119b034b",
      "metadata": {
        "id": "119b034b"
      },
      "source": [
        "---\n",
        "# **4. Inspecting Your Data (Initial Exploration) üïµÔ∏è‚Äç‚ôÄÔ∏è**\n",
        "\n",
        "Once your data is loaded, the first step is to inspect it to understand its structure, content, and quality. Pandas provides several useful functions for this:\n",
        "\n",
        "* `df.head(n)`: View the first `n` rows (default is 5).\n",
        "* `df.tail(n)`: View the last `n` rows (default is 5).\n",
        "* `df.shape`: Get the dimensions (number of rows, number of columns).\n",
        "* `df.info()`: Get a concise summary including data types, non-null values, and memory usage.\n",
        "* `df.dtypes`: Check the data type of each column.\n",
        "* `df.columns`: View the column names.\n",
        "* `df.describe()`: Generate descriptive statistics for numerical columns (count, mean, std, min, max, quartiles)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a76769",
      "metadata": {
        "id": "74a76769"
      },
      "outputs": [],
      "source": [
        "# 1. Print the first 3 rows\n",
        "print(\"First 3 rows:\")\n",
        "print(df.head(3))                   # head() returns a DataFrame, so we wrap it in print()\n",
        "\n",
        "# 2. Print the last 2 rows\n",
        "print(\"\\nLast 2 rows:\")\n",
        "print(df.tail(2))                   # tail() same as head(), needs print()\n",
        "\n",
        "# 3. Print the shape (rows, columns)\n",
        "print(\"\\nShape (rows, columns):\", df.shape)\n",
        "\n",
        "# 4. Print info (counts & data types)\n",
        "print(\"\\nInfo:\")\n",
        "df.info()                           # info() prints on its own; don‚Äôt wrap in print()\n",
        "\n",
        "# 5. Print each column‚Äôs data type\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)                    # dtypes is a Series, so we wrap it in print()\n",
        "\n",
        "# 6. Print all column names\n",
        "print(\"\\nColumns:\")\n",
        "print(list(df.columns))             # convert Index to list for cleaner printout\n",
        "\n",
        "# 7. Print descriptive stats for numeric columns\n",
        "print(\"\\nDescriptive stats:\")\n",
        "print(df.describe())                # describe() returns a DataFrame, so we wrap it in print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acccc5ce",
      "metadata": {
        "id": "acccc5ce"
      },
      "source": [
        "**Exercise 4.1:** Using the `df_students` DataFrame, display:\n",
        "1. The first 7 rows.\n",
        "2. The last 4 rows.\n",
        "3. Only the column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ddde2c",
      "metadata": {
        "id": "59ddde2c"
      },
      "outputs": [],
      "source": [
        "# Exercise 4.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8f8fdbc",
      "metadata": {
        "id": "c8f8fdbc"
      },
      "source": [
        "**Exercise 4.2:** For the `df_students` DataFrame:\n",
        "1. Get a full summary using `info()`.\n",
        "2. Get descriptive statistics for only the 'mark' column. (Hint: `df['column_name'].describe()`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ae26b6",
      "metadata": {
        "id": "37ae26b6"
      },
      "outputs": [],
      "source": [
        "# Exercise 4.2 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Basic Data Selection in Pandas (showing first 5 rows)\n",
        "\n",
        "This example shows five simple ways to grab parts of your table and see the first five results:  \n",
        "- **Columns by label (`loc`)** ‚Äì pick one (`df.loc[:, 'name']`) or two columns (`df.loc[:, ['name','mark']]`) and add `.head()`.  \n",
        "- **Columns by index (`iloc`)** ‚Äì pick the first column (`df.iloc[:, 0]`) or first two columns (`df.iloc[:, 0:2]`) and add `.head()`.  \n",
        "- **Rows by label (`loc`)** ‚Äì get a single row (`df.loc[2]`), an inclusive range (`df.loc[2:4]`), or specific rows (`df.loc[[0,3,5]]`), using `.head()` when you have multiple.  \n",
        "- **Rows by position (`iloc`)** ‚Äì grab the second row (`df.iloc[1]`), a slice of rows (`df.iloc[0:3]`), or a list (`df.iloc[[0,3,5]]`), with `.head()` for multi-row outputs.  \n",
        "- **Rows & columns by position (`iloc`)** ‚Äì slice rows and columns at once, e.g. `df.iloc[0:3, 0:2].head()` to see the first three rows and two columns.  \n"
      ],
      "metadata": {
        "id": "hoYDvYruovU8"
      },
      "id": "hoYDvYruovU8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd4e046d",
      "metadata": {
        "id": "bd4e046d"
      },
      "outputs": [],
      "source": [
        "# 1. Select columns by label with loc\n",
        "one_col   = df.loc[:, 'name']              # Single column ‚Üí Series\n",
        "two_cols  = df.loc[:, ['name', 'mark']]    # Two columns ‚Üí DataFrame\n",
        "\n",
        "print(\"1. Names (first 5):\")\n",
        "print(one_col.head(), \"\\n\")\n",
        "\n",
        "print(\"2. Name & Mark (first 5):\")\n",
        "print(two_cols.head(), \"\\n\")\n",
        "\n",
        "\n",
        "# 2. Select rows by label with loc\n",
        "row_2     = df.loc[2]                      # Row with index label 2\n",
        "rows_2_4  = df.loc[2:4]                    # Rows 2,3,4 (inclusive)\n",
        "some_rows = df.loc[[0, 3, 5]]              # Specific rows by label\n",
        "\n",
        "print(\"3. Row at label 2:\")\n",
        "print(row_2, \"\\n\")\n",
        "\n",
        "print(\"4. Rows 2‚Äì4 (first 5 of that slice):\")\n",
        "print(rows_2_4.head(), \"\\n\")\n",
        "\n",
        "print(\"5. Rows [0, 3, 5] (first 5):\")\n",
        "print(some_rows.head(), \"\\n\")\n",
        "\n",
        "\n",
        "# 3. Select columns by position with iloc\n",
        "col_0      = df.iloc[:, 0]              # First column ‚Üí Series\n",
        "cols_0_2   = df.iloc[:, 0:2]            # First two columns ‚Üí DataFrame\n",
        "some_cols  = df.iloc[:, [0, 2]]         # First and third columns ‚Üí DataFrame\n",
        "\n",
        "print(\"6. Column at position 0 (first 5):\")\n",
        "print(col_0.head(), \"\\n\")\n",
        "\n",
        "print(\"7. Columns 0‚Äì1 (first 5):\")\n",
        "print(cols_0_2.head(), \"\\n\")\n",
        "\n",
        "print(\"8. Columns at positions [0, 2] (first 5):\")\n",
        "print(some_cols.head(), \"\\n\")\n",
        "\n",
        "\n",
        "# 4. Select rows by position with iloc\n",
        "row_pos1  = df.iloc[1]                     # Second row (position 1)\n",
        "rows_0_2  = df.iloc[0:3]                   # Rows 0,1,2 (end exclusive)\n",
        "some_pos  = df.iloc[[0, 3, 5]]             # Specific rows by position\n",
        "\n",
        "print(\"9. Row at position 1:\")\n",
        "print(row_pos1, \"\\n\")\n",
        "\n",
        "print(\"10. Rows 0‚Äì2 (first 5 of that slice):\")\n",
        "print(rows_0_2.head(), \"\\n\")\n",
        "\n",
        "print(\"11. Positions [0, 3, 5] (first 5):\")\n",
        "print(some_pos.head(), \"\\n\")\n",
        "\n",
        "\n",
        "# 5. Combine row & column selection\n",
        "sub_loc   = df.loc[1:3, ['name', 'class']] # Labels 1‚Äì3, columns name & class\n",
        "sub_iloc  = df.iloc[0:3, 0:2]              # First 3 rows, first 2 columns\n",
        "\n",
        "print(\"12. loc rows 1‚Äì3 & cols name,class (first 5):\")\n",
        "print(sub_loc.head(), \"\\n\")\n",
        "\n",
        "print(\"13. iloc rows 0‚Äì3 & cols 0‚Äì2 (first 5):\")\n",
        "print(sub_iloc.head(), \"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f179b185",
      "metadata": {
        "id": "f179b185"
      },
      "source": [
        "**Exercise 5.1:** From `df_students`:\n",
        "1. Select and display only the 'class' column.\n",
        "2. Select and display the 'name', 'mark', and 'gender' columns for all students."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1cf4834",
      "metadata": {
        "id": "a1cf4834"
      },
      "outputs": [],
      "source": [
        "# Exercise 5.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b279590",
      "metadata": {
        "id": "8b279590"
      },
      "source": [
        "**Exercise 5.2:** From `df_students`:\n",
        "1. Using `loc`, select the data for students at index positions 2, 4, and 6 (if these indices exist in your DataFrame's index), showing only their 'name' and 'mark'.\n",
        "2. Using `iloc`, select the students in rows 0 through 4 (inclusive for start, exclusive for end for `iloc`) and columns 1 through 3 (exclusive for end for `iloc`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "443632e0",
      "metadata": {
        "id": "443632e0"
      },
      "outputs": [],
      "source": [
        "# Exercise 5.2 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef72fa2d",
      "metadata": {
        "id": "ef72fa2d"
      },
      "source": [
        "### **6. Filtering DataFrames (Simple Conditions)**\n",
        "\n",
        "Filtering in pandas means selecting specific rows from your data based on a rule or condition. This is useful when you want to look at a smaller part of your data that meets certain criteria.\n",
        "\n",
        "For example, you might want to see:\n",
        "- only the students who scored more than 80\n",
        "- only the students who are in class \"Four\"\n",
        "- only the students who scored less than 60\n",
        "\n",
        "#### Basic Syntax\n",
        "\n",
        "df[condition]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d071769",
      "metadata": {
        "id": "6d071769"
      },
      "outputs": [],
      "source": [
        "# Students with marks greater than 80\n",
        "high_scorers = df[df['mark'] > 80]\n",
        "print(\"Students with mark > 80:\\n\", high_scorers)\n",
        "\n",
        "# Students in class 'Four'\n",
        "class_four = df[df['class'] == 'Four']\n",
        "print(\"\\nStudents in class 'Four':\\n\", class_four)\n",
        "\n",
        "# Students with marks less than 60\n",
        "low_mark = df[df['mark'] < 60]\n",
        "print(\"\\nStudents with mark < 60:\\n\", low_mark)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bca0a8a",
      "metadata": {
        "id": "7bca0a8a"
      },
      "source": [
        "**Exercise 6.1:** From `df_students`, select and display:\n",
        "1. All students who are 'male'.\n",
        "2. All students whose 'mark' is exactly 78."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9963afd0",
      "metadata": {
        "id": "9963afd0"
      },
      "outputs": [],
      "source": [
        "# Exercise 6.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "313e2824",
      "metadata": {
        "id": "313e2824"
      },
      "source": [
        "**Exercise 6.2:** From `df_students`, select and display:\n",
        "1. All 'female' students who have a 'mark' greater than or equal to 70.\n",
        "2. All students who are in 'class' 'Six' OR 'class' 'Seven'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "140b8273",
      "metadata": {
        "id": "140b8273"
      },
      "outputs": [],
      "source": [
        "# Exercise 6.2 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f34118",
      "metadata": {
        "id": "89f34118"
      },
      "source": [
        "---\n",
        "# **7. Data Cleaning**\n",
        "\n",
        "Real-world data is often messy. Data cleaning involves handling inconsistencies, errors, and missing data.\n",
        "\n",
        "# **7.1. Handling Missing Values (`NaN`)**\n",
        "Missing values are usually represented as `NaN` (Not a Number).\n",
        "\n",
        "* **Detecting missing values:** `df.isnull()` (returns a boolean DataFrame) or `df.isnull().sum()` (counts missing values per column).\n",
        "* **Dropping missing values:** `df.dropna()` (drops rows with any NaN).\n",
        "    * `axis=1` drops columns with NaN.\n",
        "    * `how='all'` drops rows/columns if all values are NaN.\n",
        "    * `thresh=N` keeps rows/columns with at least N non-NaN values.\n",
        "* **Filling missing values:** `df.fillna(value)`\n",
        "    * Fill with a specific value (0, 'Unknown', etc.).\n",
        "    * Fill with mean: `df['column'].fillna(df['column'].mean())`.\n",
        "    * Fill with median: `df['column'].fillna(df['column'].median())`.\n",
        "    * Fill with mode: `df['column'].fillna(df['column'].mode()[0])` (mode can return multiple values, so take the first).\n",
        "    * `method='ffill'` (forward fill) or `method='bfill'` (backward fill)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd04ea0",
      "metadata": {
        "id": "8fd04ea0"
      },
      "outputs": [],
      "source": [
        "# Example: Basic data cleaning with Pandas\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: View the original shape and check for missing values\n",
        "# -------------------------------\n",
        "print(\"Original data shape (rows, columns):\")\n",
        "print(df.shape)\n",
        "\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: Remove rows with missing data\n",
        "# -------------------------------\n",
        "df_no_missing = df.copy()\n",
        "df_no_missing = df_no_missing.dropna()\n",
        "\n",
        "print(\"\\nData shape after dropping rows with missing values:\")\n",
        "print(df_no_missing.shape)\n",
        "print(\"Missing values after dropping:\")\n",
        "print(df_no_missing.isnull().sum())\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Fill missing values\n",
        "# -------------------------------\n",
        "df_filled = df.copy()\n",
        "\n",
        "# Convert 'mark' to numeric, turn errors into NaN\n",
        "df_filled['mark'] = pd.to_numeric(df_filled['mark'], errors='coerce')\n",
        "\n",
        "# Fill missing marks with the average (mean) value\n",
        "mean_mark = df_filled['mark'].mean()\n",
        "df_filled['mark'] = df_filled['mark'].fillna(mean_mark)\n",
        "\n",
        "# Fill missing gender values with 'Unknown'\n",
        "df_filled['gender'] = df_filled['gender'].fillna('Unknown')\n",
        "\n",
        "print(\"\\nMissing values after filling:\")\n",
        "print(df_filled.isnull().sum())\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Remove duplicate rows\n",
        "# -------------------------------\n",
        "df_no_duplicates = df_filled.copy()\n",
        "\n",
        "# Drop duplicate rows\n",
        "df_no_duplicates = df_no_duplicates.drop_duplicates()\n",
        "\n",
        "print(\"\\nShape after removing duplicate rows:\")\n",
        "print(df_no_duplicates.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75b83843",
      "metadata": {
        "id": "75b83843"
      },
      "source": [
        "### Exercise: Handling Missing Values\n",
        "\n",
        "Use a fresh copy of the DataFrame `df`.\n",
        "\n",
        "1. Count the total number of missing values in the entire DataFrame.  \n",
        "   üí° *Hint:* Use `df.isnull().sum().sum()` to get the total number.\n",
        "\n",
        "2. Fill the missing values in the **`gender`** column with the most common value (called the **mode**).  \n",
        "   üí° *Hint:* Use `df['gender'].mode()[0]` to get the most frequent value.\n",
        "\n",
        "3. Print the number of missing values again using `df.isnull().sum()` to check the result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "724c6f81",
      "metadata": {
        "id": "724c6f81"
      },
      "outputs": [],
      "source": [
        "# Exercise 7.1.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo solution\n",
        "# Step 1: Make a fresh copy of the data\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Step 2: Count total missing values\n",
        "print(\"Total missing values:\", df_clean.isnull().sum().sum())\n",
        "\n",
        "# Step 3: Fill missing gender values with the mode\n",
        "most_common_gender = df_clean['gender'].mode()[0]\n",
        "df_clean['gender'] = df_clean['gender'].fillna(most_common_gender)\n",
        "\n",
        "# Step 4: Check missing values again\n",
        "print(\"\\nMissing values after filling 'gender':\")\n",
        "print(df_clean.isnull().sum())\n"
      ],
      "metadata": {
        "id": "i8btp-W4vjuf"
      },
      "id": "i8btp-W4vjuf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fd2d7a44",
      "metadata": {
        "id": "fd2d7a44"
      },
      "source": [
        "# **7.2. Renaming Columns**\n",
        "You can rename columns using `df.rename(columns={'old_name': 'new_name', ...}, inplace=True)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac0b3a94",
      "metadata": {
        "id": "ac0b3a94"
      },
      "outputs": [],
      "source": [
        "# Example: Renaming columns in a DataFrame\n",
        "\n",
        "# Make a copy of the original DataFrame\n",
        "df_renamed = df.copy()\n",
        "\n",
        "# Rename the columns 'class' to 'student_class' and 'mark' to 'score'\n",
        "df_renamed.rename(columns={'class': 'student_class', 'mark': 'score'}, inplace=True)\n",
        "\n",
        "# Print the new column names\n",
        "print(\"Columns after renaming:\", df_renamed.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d185c2d",
      "metadata": {
        "id": "7d185c2d"
      },
      "source": [
        "# **8. Data Transformation**\n",
        "\n",
        "Data transformation is the process of modifying the structure or values of a DataFrame to make the data more useful or meaningful. This often includes creating new columns, changing data types, or preparing values for analysis.\n",
        "---\n",
        "\n",
        "## **8.1. Creating New Columns**\n",
        "\n",
        "In this example, we perform several transformations to clean and enrich the dataset step by step.\n",
        "\n",
        "### **Step 1: Make a Copy of the Original DataFrame**\n",
        "\n",
        "Before making any changes, it's a good practice to work on a copy of the original DataFrame to avoid altering the original data.\n",
        "\n",
        "# Make a copy of the original DataFrame\n",
        "df_transformed = df.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644aa144",
      "metadata": {
        "id": "644aa144"
      },
      "outputs": [],
      "source": [
        "# Example: Creating new columns in a DataFrame\n",
        "\n",
        "# Make a copy of the original DataFrame\n",
        "df_transformed = df.copy()\n",
        "\n",
        "# Convert 'mark' to numeric and fill any missing values with 0\n",
        "df_transformed['mark'] = pd.to_numeric(df_transformed['mark'], errors='coerce').fillna(0)\n",
        "\n",
        "# Create a new column: 'mark_percentage' (assuming max mark is 100)\n",
        "df_transformed['mark_percentage'] = df_transformed['mark']\n",
        "\n",
        "# Create a new column: 'pass_fail' (Pass if mark >= 60)\n",
        "df_transformed['pass_fail'] = df_transformed['mark'].apply(lambda x: 'Pass' if x >= 60 else 'Fail')\n",
        "\n",
        "# Display the result\n",
        "print(df_transformed[['name', 'mark', 'mark_percentage', 'pass_fail']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5008fd41",
      "metadata": {
        "id": "5008fd41"
      },
      "source": [
        "**Exercise 8.1:** In a copy of `df` (ensure 'mark' is numeric and NaNs are handled, e.g., filled with 0 for this exercise):\n",
        "1. Create a new column called `bonus_mark` which is 10% of the original 'mark'.\n",
        "2. Create another column `final_mark` which is the sum of 'mark' and `bonus_mark`.\n",
        "3. Print the 'name', 'mark', `bonus_mark`, and `final_mark` columns for the first 5 students."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ab5374",
      "metadata": {
        "id": "39ab5374"
      },
      "outputs": [],
      "source": [
        "# Exercise 8.1.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a02a37ef",
      "metadata": {
        "id": "a02a37ef"
      },
      "source": [
        "---\n",
        "# **9. Basic Statistics and Aggregation üìä**\n",
        "\n",
        "Pandas makes it easy to get insights from your data through statistics and aggregation.\n",
        "\n",
        "* `df['column'].value_counts()`: Counts of unique values in a Series (good for categorical data).\n",
        "* Basic statistics on Series/DataFrame columns:\n",
        "    * `df['column'].mean()`\n",
        "    * `df['column'].median()`\n",
        "    * `df['column'].min()`, `df['column'].max()`\n",
        "    * `df['column'].std()` (standard deviation)\n",
        "    * `df['column'].sum()`\n",
        "    * `df['column'].count()` (non-null values)\n",
        "* `df.groupby('column_to_group_by')`: Groups data based on categories in a column. You can then apply aggregate functions (like mean, sum, count) to the groups.\n",
        "    * Example: `df.groupby('class')['mark'].mean()` (average mark per class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5602db5",
      "metadata": {
        "id": "a5602db5"
      },
      "outputs": [],
      "source": [
        "# Example 9.1: Statistics and Aggregation\n",
        "\n",
        "# Convert 'mark' column to numeric\n",
        "df['mark'] = pd.to_numeric(df['mark'], errors='coerce')\n",
        "\n",
        "# Value counts for 'class'\n",
        "print(\"Class distribution:\")\n",
        "print(df['class'].value_counts())\n",
        "\n",
        "# Basic statistics\n",
        "print(\"\\nMean mark:\", df['mark'].mean())\n",
        "print(\"Median mark:\", df['mark'].median())\n",
        "print(\"Highest mark:\", df['mark'].max())\n",
        "print(\"Lowest mark:\", df['mark'].min())\n",
        "\n",
        "# Mean mark per class\n",
        "print(\"\\nAverage mark per class:\")\n",
        "print(df.groupby('class')['mark'].mean())\n",
        "\n",
        "# Student count per gender (filling missing values with 'Unknown')\n",
        "print(\"\\nStudents per gender:\")\n",
        "print(df.fillna({'gender': 'Unknown'}).groupby('gender')['id'].count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742fd896",
      "metadata": {
        "id": "742fd896"
      },
      "source": [
        "**Exercise 9.1:** Using `df`:\n",
        "1. Get the value counts for the 'gender' column.\n",
        "2. Calculate and print the percentage of each gender using `value_counts(normalize=True) * 100`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15fb59c9",
      "metadata": {
        "id": "15fb59c9"
      },
      "outputs": [],
      "source": [
        "# Exercise 9.1 Code Cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0935aa29",
      "metadata": {
        "id": "0935aa29"
      },
      "source": [
        "---\n",
        "# **10. Basic Visualizations üìàüìâ**\n",
        "\n",
        "Visualizations help in understanding data patterns and trends. Pandas integrates with Matplotlib for plotting.\n",
        "Remember we imported `matplotlib.pyplot as plt`.\n",
        "\n",
        "# **10.1. Histograms**\n",
        "Histograms show the distribution of a numerical variable.\n",
        "`df['column'].plot(kind='hist', title='My Histogram', bins=10)`\n",
        "`plt.xlabel('X-axis Label')`\n",
        "`plt.ylabel('Frequency')`\n",
        "`plt.show()`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f40011",
      "metadata": {
        "id": "f4f40011"
      },
      "source": [
        "# **10. Basic Visualization**\n",
        "\n",
        "Visualising data helps you quickly identify patterns, trends, and outliers. Pandas integrates with Matplotlib for simple and effective plotting. Below are common visualisation types using only Pandas:\n",
        "\n",
        "- **Bar Chart**: Displays the count of categories or frequency of values.\n",
        "- **Line Plot**: Shows how a variable changes over an index (e.g. time or order).\n",
        "- **Scatter Plot**: Explores the relationship between two numerical variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3ffeb2",
      "metadata": {
        "id": "3f3ffeb2"
      },
      "source": [
        "# **10.1. Bar Plots**\n",
        "Bar plots are useful for comparing categorical data.\n",
        "`df['column'].value_counts().plot(kind='bar', title='My Bar Plot')`\n",
        "`plt.xlabel('Categories')`\n",
        "`plt.ylabel('Count')`\n",
        "`plt.xticks(rotation=45)` (to rotate x-axis labels if they overlap)\n",
        "`plt.show()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb89bee",
      "metadata": {
        "id": "deb89bee"
      },
      "outputs": [],
      "source": [
        "# Bar graph of student counts per class using only pandas\n",
        "df['class'].value_counts().plot.bar().figure.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10.2. Line Plots**\n",
        "\n",
        "Line plots show how a numerical variable changes over an index or time. They are useful for visualising trends and patterns in data sequences.  \n",
        "`df['column'].plot(title='My Line Plot')`  \n",
        "`plt.show()`\n"
      ],
      "metadata": {
        "id": "hIKDVtAz2ICY"
      },
      "id": "hIKDVtAz2ICY"
    },
    {
      "cell_type": "code",
      "source": [
        "# Line plot of student marks using only pandas\n",
        "df['mark'].plot(title='Line Plot of Student Marks').figure.show()\n"
      ],
      "metadata": {
        "id": "PYHQlzbo2UQa"
      },
      "id": "PYHQlzbo2UQa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e1641370",
      "metadata": {
        "id": "e1641370"
      },
      "source": [
        "# **10.3. Scatter Plots**\n",
        "Scatter plots show the relationship between two numerical variables.\n",
        "`df.plot.scatter(x='col1', y='col2', title='My Scatter Plot')`\n",
        "`plt.show()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9912449",
      "metadata": {
        "id": "c9912449"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a DataFrame with random data\n",
        "df = pd.DataFrame({\n",
        "    'x': np.random.randint(1, 100, size=50),\n",
        "    'y': np.random.randint(1, 100, size=50)\n",
        "})\n",
        "\n",
        "# Create scatter plot using only pandas\n",
        "df.plot.scatter(x='x', y='y', title='Scatter Plot of Random Values').figure.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18add858",
      "metadata": {
        "id": "18add858"
      },
      "source": [
        "# **Group Activity: Choosing the Right Plot**\n",
        "\n",
        "**Scenario:** Working with the `df` dataset, discuss the following questions with your group. For each one, decide which type of plot (Bar Plot, Line Plot, or Scatter Plot) would be the most suitable to answer the question ‚Äî and explain why.\n",
        "\n",
        "1. How many students are there in each `'class'`?\n",
        "2. What does the overall distribution of student `'marks'` look like? Are the marks generally high, low, or spread out?\n",
        "3. Is there a relationship between a student's `'id'` and their `'mark'`? (Assume `'id'` represents enrolment order or time sequence).\n",
        "4. How do the numbers of `'male'` and `'female'` students compare?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "cbe0861b",
      "metadata": {
        "id": "cbe0861b"
      },
      "outputs": [],
      "source": [
        "# Group Activity Answers\n",
        "\n",
        "# 1. How many students are there in each 'class'?\n",
        "#    - Appropriate plot: Bar Plot\n",
        "#    - Reason: A bar plot is ideal for showing the number of students in each category of the 'class' column.\n",
        "# Example:\n",
        "# df_students['class'].value_counts().plot(kind='bar', title='Students per Class').figure.show()\n",
        "\n",
        "# 2. What is the overall distribution of student 'marks'?\n",
        "#    - Appropriate plot: Histogram\n",
        "#    - Reason: A histogram shows how marks are distributed (e.g. skewed, spread out, or clustered).\n",
        "# Example:\n",
        "# pd.to_numeric(df_students['mark'], errors='coerce').dropna().plot(kind='hist', title='Mark Distribution').figure.show()\n",
        "\n",
        "# 3. Is there a relationship between a student's 'id' and their 'mark'?\n",
        "#    - Appropriate plot: Scatter Plot\n",
        "#    - Reason: A scatter plot shows the relationship or correlation between two numeric variables.\n",
        "# Example:\n",
        "# df_students.dropna(subset=['id', 'mark']).plot.scatter(x='id', y='mark', title='ID vs Mark').figure.show()\n",
        "\n",
        "# 4. How do the numbers of 'male' and 'female' students compare?\n",
        "#    - Appropriate plot: Bar Plot\n",
        "#    - Reason: A bar plot is useful for comparing the counts of categorical values like gender.\n",
        "# Example:\n",
        "# df_students['gender'].fillna('Unknown').value_counts().plot(kind='bar', title='Gender Comparison').figure.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99e8d6d8",
      "metadata": {
        "id": "99e8d6d8"
      },
      "source": [
        "---\n",
        "# **11. Best Practices Recap**\n",
        "\n",
        "* **Clear Variable Names:** Use descriptive names for DataFrames and Series (e.g., `df_students`, `mean_score`).\n",
        "* **Comment Your Code:** Explain complex steps or a non-obvious logic with `#` comments.\n",
        "* **Inspect Frequently:** Use `.head()`, `.info()`, `.shape`, `.describe()` often to check your data and the results of operations.\n",
        "* **Work on Copies:** When performing operations that modify a DataFrame (especially `inplace=True` or tricky transformations), it's often safer to work on a copy: `df_copy = df.copy()`.\n",
        "* **Break Down Problems:** For complex tasks, break them into smaller, manageable steps.\n",
        "* **Understand Your Data Types:** Ensure columns have the correct data types for the operations you want to perform."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe67b52",
      "metadata": {
        "id": "7fe67b52"
      },
      "source": [
        "---\n",
        "# **üéâ Day 3 Wrap-up**\n",
        "\n",
        "Congratulations! You've learned the fundamentals of data analysis using Pandas. You can now:\n",
        "* Create and understand Series and DataFrames.\n",
        "* Load data from CSV files.\n",
        "* Inspect, clean, and transform datasets.\n",
        "* Calculate basic statistics and perform aggregations.\n",
        "* Create simple visualizations to explore your data.\n",
        "\n",
        "**Keep practicing!** The more you work with data, the more comfortable you'll become with Pandas. Try these techniques on different datasets or explore more advanced Pandas features.\n",
        "\n",
        "**Next Steps:** We'll build upon these skills to tackle more complex data analysis tasks and possibly explore other libraries like Seaborn for more advanced visualizations."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}